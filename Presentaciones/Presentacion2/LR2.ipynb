{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión logística y la regularización L1\n",
    "\n",
    "La regularización L1 (también llamada desviaciones mínimas absolutas) es una poderosa herramienta en la ciencia de datos. Mostremos el efecto del parámetro de regularización C en los coeficientes y la precisión del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargando datos\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Reescribimos la variable donde la categoria no es 2\n",
    "X = X[y != 2]\n",
    "y = y[y != 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vista de caracteristicas\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vista de la data objetivo\n",
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos los datos: 30% de estos son del conjunto de prueba\n",
    "X_entrenamiento, X_prueba, y_entrenamiento, y_prueba = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a que la penalización de regularización está compuesta por la suma del valor absoluto de los coeficientes, necesitamos escalar los datos para que los coeficientes estén todos en la misma escala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un objeto escalador\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Fijamos el escalador a los datos de entrenamiento y transformamos\n",
    "X_entrenamiento_std = sc.fit_transform(X_entrenamiento)\n",
    "\n",
    "# Aplicamos el escalador a los datos de prueba\n",
    "X_prueba_std = sc.transform(X_prueba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutamos la regresión logística con una penalización L1.\n",
    "La utilidad de L1 es que puede llevar los coeficientes de característica a 0, creando un método para la selección de características. En el siguiente código ejecutamos una regresión logística con una penalización L1 cuatro veces, cada vez disminuyendo el valor de C. \n",
    "\n",
    "Debemos esperar que C disminuya, para que más coeficientes se conviertan en 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 10\n",
      "Coeficiente para cada  caracteristica: [[-0.01669188 -3.8502164   4.36910299  0.        ]]\n",
      "Precision de entrenamiento: 1.0\n",
      "Precision de prueba: 1.0\n",
      "\n",
      "C: 1\n",
      "Coeficiente para cada  caracteristica: [[ 0.         -2.28845282  2.57677378  0.        ]]\n",
      "Precision de entrenamiento: 1.0\n",
      "Precision de prueba: 1.0\n",
      "\n",
      "C: 0.1\n",
      "Coeficiente para cada  caracteristica: [[ 0.         -0.82312853  0.97172196  0.        ]]\n",
      "Precision de entrenamiento: 1.0\n",
      "Precision de prueba: 1.0\n",
      "\n",
      "C: 0.001\n",
      "Coeficiente para cada  caracteristica: [[0. 0. 0. 0.]]\n",
      "Precision de entrenamiento: 0.5\n",
      "Precision de prueba: 0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "C = [10, 1, .1, .001]\n",
    "\n",
    "for c in C:\n",
    "    clf = LogisticRegression(penalty='l1', C=c)\n",
    "    clf.fit(X_entrenamiento, y_entrenamiento)\n",
    "    print('C:', c)\n",
    "    print('Coeficiente para cada  caracteristica:', clf.coef_)\n",
    "    print('Precision de entrenamiento:', clf.score(X_entrenamiento, y_entrenamiento))\n",
    "    print('Precision de prueba:', clf.score(X_prueba, y_prueba))\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observa que a medida que C disminuye los coeficientes del modelo se vuelven más pequeños (por ejemplo, de 4.36276075 cuando C = 10 a 0.0.97175097 cuando C = 0.1), hasta que en C = 0.001 todos los coeficientes son cero. Este es el efecto de la penalización de regularización cada vez más prominente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
